"""
E-E-A-T Analyzer
Analyzes Expertise, Experience, Authoritativeness, and Trustworthiness signals
"""

import re
from typing import List, Dict, Tuple, Optional
from bs4 import BeautifulSoup


class EEATAnalyzer:
    """Analyzes E-E-A-T signals in content"""
    
    def __init__(self):
        # Website type detection keywords
        self.educational_keywords = [
            'Ø¢Ù…ÙˆØ²Ø´', 'Ø¯ÙˆØ±Ù‡', 'course', 'training', 'learn', 'tutorial', 'Ø¢Ù…ÙˆØ²Ø´Ú¯Ø§Ù‡',
            'Ù…Ø¯Ø±Ø³', 'instructor', 'teacher', 'Ø§Ø³ØªØ§Ø¯', 'Ú©Ù„Ø§Ø³', 'class', 'workshop',
            'Ú¯ÙˆØ§Ù‡ÛŒÙ†Ø§Ù…Ù‡', 'certificate', 'certification', 'Ø¯ÛŒÙ¾Ù„Ù…', 'diploma'
        ]
        
        self.medical_keywords = [
            'Ø¯Ú©ØªØ±', 'Ù¾Ø²Ø´Ú©', 'Ù…ØªØ®ØµØµ', 'doctor', 'specialist', 'medical',
            'Ø¨ÛŒÙ…Ø§Ø±Ø³ØªØ§Ù†', 'hospital', 'Ú©Ù„ÛŒÙ†ÛŒÚ©', 'clinic', 'Ø¯Ø±Ù…Ø§Ù†', 'treatment',
            'Ø¬Ø±Ø§Ø­ÛŒ', 'surgery', 'Ø¨ÛŒÙ…Ø§Ø±', 'patient', 'Ù†Ø¸Ø§Ù… Ù¾Ø²Ø´Ú©ÛŒ'
        ]
        
        self.ecommerce_keywords = [
            'Ø®Ø±ÛŒØ¯', 'ÙØ±ÙˆØ´', 'buy', 'sell', 'product', 'Ù…Ø­ØµÙˆÙ„', 'Ù‚ÛŒÙ…Øª', 'price',
            'Ø³ÙØ§Ø±Ø´', 'order', 'Ø³Ø¨Ø¯ Ø®Ø±ÛŒØ¯', 'cart', 'checkout'
        ]
        
        # Expertise signals (Persian and English)
        self.expertise_keywords = [
            'Ø¯Ú©ØªØ±', 'Ù¾Ø²Ø´Ú©', 'Ù…ØªØ®ØµØµ', 'doctor', 'specialist', 'expert',
            'md', 'phd', 'Ø§Ø³ØªØ§Ø¯', 'professor', 'Ø¯Ø§Ù†Ø´ÛŒØ§Ø±',
            'Ù…Ø¯Ø±Ú©', 'certificate', 'Ú¯ÙˆØ§Ù‡ÛŒÙ†Ø§Ù…Ù‡', 'board certified',
            'ÙÙ„ÙˆØ´ÛŒÙ¾', 'fellowship', 'Ø±Ø²ÛŒØ¯Ù†Øª', 'resident',
            'Ù…Ø¯Ø±Ø³', 'instructor', 'teacher', 'trainer', 'coach'
        ]
        
        # Authority signals
        self.authority_keywords = [
            'Ù…Ù†Ø¨Ø¹', 'Ù…Ø±Ø¬Ø¹', 'source', 'reference', 'Ø§Ø³ØªÙ†Ø§Ø¯', 'citation',
            'ØªØ­Ù‚ÛŒÙ‚', 'research', 'Ù…Ø·Ø§Ù„Ø¹Ù‡', 'study', 'pubmed',
            'Ø§Ù†Ø¬Ù…Ù†', 'association', 'Ø³Ø§Ø²Ù…Ø§Ù†', 'organization',
            'ÙˆØ²Ø§Ø±Øª Ø¨Ù‡Ø¯Ø§Ø´Øª', 'ministry of health', 'fda', 'who'
        ]
        
        # Trust signals
        self.trust_keywords = [
            'ØªØ¶Ù…ÛŒÙ†', 'guarantee', 'Ø¶Ù…Ø§Ù†Øª', 'warranty',
            'Ø¨ÛŒÙ…Ù‡', 'insurance', 'Ù…Ø¬ÙˆØ²', 'license',
            'Ù†Ø¸Ø§Ù… Ù¾Ø²Ø´Ú©ÛŒ', 'medical council', 'Ø±Ø³Ù…ÛŒ', 'official',
            'ØªØ§ÛŒÛŒØ¯ Ø´Ø¯Ù‡', 'verified', 'certified'
        ]
        
        # Experience signals
        self.experience_keywords = [
            'Ø³Ø§Ø¨Ù‚Ù‡', 'ØªØ¬Ø±Ø¨Ù‡', 'experience', 'years',
            'Ù†Ù…ÙˆÙ†Ù‡ Ú©Ø§Ø±', 'portfolio', 'Ù‚Ø¨Ù„ Ùˆ Ø¨Ø¹Ø¯', 'before after',
            'Ù…Ø±Ø§Ø¬Ø¹ÛŒÙ†', 'patients', 'Ø¨ÛŒÙ…Ø§Ø±Ø§Ù†', 'clients',
            'Ù…ÙˆÙÙ‚', 'successful', 'Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡', 'performed'
        ]
    
    def analyze_eeat(self, soup: BeautifulSoup, url: str) -> Dict[str, any]:
        """
        Comprehensive E-E-A-T analysis
        
        Args:
            soup: BeautifulSoup object of the page
            url: Page URL
            
        Returns:
            Dictionary with E-E-A-T scores and signals
        """
        text = soup.get_text().lower()
        
        # Detect website type
        website_type = self._detect_website_type(soup, text, url)
        
        # Analyze each component
        expertise = self._analyze_expertise(soup, text)
        experience = self._analyze_experience(soup, text)
        authoritativeness = self._analyze_authoritativeness(soup, text, url)
        trustworthiness = self._analyze_trustworthiness(soup, text)
        
        # Calculate overall score
        overall_score = (
            expertise['score'] * 0.3 +
            experience['score'] * 0.25 +
            authoritativeness['score'] * 0.25 +
            trustworthiness['score'] * 0.2
        )
        
        # Generate recommendations for each component (based on website type)
        expertise['recommendations'] = self._generate_expertise_recommendations(expertise, soup, text, website_type)
        experience['recommendations'] = self._generate_experience_recommendations(experience, soup, text, website_type)
        authoritativeness['recommendations'] = self._generate_authoritativeness_recommendations(authoritativeness, soup, text, website_type)
        trustworthiness['recommendations'] = self._generate_trustworthiness_recommendations(trustworthiness, soup, text, website_type)
        
        return {
            'overall_score': round(overall_score, 1),
            'overall_grade': self._get_grade(overall_score),
            'website_type': website_type,
            'expertise': expertise,
            'experience': experience,
            'authoritativeness': authoritativeness,
            'trustworthiness': trustworthiness,
            'recommendations': self._generate_recommendations(expertise, experience, authoritativeness, trustworthiness)
        }
    
    def _analyze_expertise(self, soup: BeautifulSoup, text: str) -> Dict:
        """Analyze expertise signals"""
        signals_found = []
        score = 0
        
        # Check for expertise keywords
        for keyword in self.expertise_keywords:
            if keyword in text:
                signals_found.append(keyword)
                score += 10
        
        # Check for author bio section
        author_sections = soup.find_all(['section', 'div'], class_=re.compile(r'author|writer|bio', re.I))
        if author_sections:
            signals_found.append('author_bio_section')
            score += 15
        
        # Check for credentials in schema
        scripts = soup.find_all('script', type='application/ld+json')
        for script in scripts:
            try:
                import json
                data = json.loads(script.string)
                if isinstance(data, dict):
                    # Check for Person schema with credentials
                    if data.get('@type') == 'Person' or 'author' in data:
                        signals_found.append('author_schema')
                        score += 20
            except:
                pass
        
        # Check for educational background mentions
        education_patterns = [
            r'Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡\s+[\w\s]+',
            r'university\s+of\s+[\w\s]+',
            r'Ø¯Ø§Ù†Ø´Ú©Ø¯Ù‡\s+Ù¾Ø²Ø´Ú©ÛŒ',
            r'medical\s+school'
        ]
        
        for pattern in education_patterns:
            if re.search(pattern, text, re.I):
                signals_found.append('educational_background')
                score += 10
                break
        
        # Normalize score to 0-100
        score = min(score, 100)
        
        return {
            'score': score,
            'grade': self._get_grade(score),
            'signals_found': signals_found,
            'signal_count': len(signals_found)
        }
    
    def _analyze_experience(self, soup: BeautifulSoup, text: str) -> Dict:
        """Analyze experience signals"""
        signals_found = []
        score = 0
        
        # Check for experience keywords
        for keyword in self.experience_keywords:
            if keyword in text:
                signals_found.append(keyword)
                score += 8
        
        # Check for portfolio/before-after images
        images = soup.find_all('img')
        portfolio_images = [
            img for img in images
            if any(term in img.get('alt', '').lower() for term in ['Ù‚Ø¨Ù„', 'Ø¨Ø¹Ø¯', 'before', 'after', 'Ù†Ù…ÙˆÙ†Ù‡'])
        ]
        
        if portfolio_images:
            signals_found.append('portfolio_images')
            score += 20
        
        # Check for testimonials/reviews
        review_sections = soup.find_all(['div', 'section'], class_=re.compile(r'review|testimonial|Ù†Ø¸Ø±', re.I))
        if review_sections:
            signals_found.append('testimonials')
            score += 15
        
        # Check for case studies
        if re.search(r'Ù…ÙˆØ±Ø¯\s+\d+', text) or re.search(r'\d+\s+cases?', text):
            signals_found.append('case_numbers')
            score += 10
        
        # Check for years of experience
        years_pattern = r'(\d+)\s*(Ø³Ø§Ù„|year).*?(ØªØ¬Ø±Ø¨Ù‡|Ø³Ø§Ø¨Ù‚Ù‡|experience)'
        years_match = re.search(years_pattern, text, re.I)
        if years_match:
            years = int(years_match.group(1))
            signals_found.append(f'{years}_years_experience')
            score += min(years * 2, 25)  # Max 25 points
        
        # Normalize score
        score = min(score, 100)
        
        return {
            'score': score,
            'grade': self._get_grade(score),
            'signals_found': signals_found,
            'signal_count': len(signals_found)
        }
    
    def _analyze_authoritativeness(self, soup: BeautifulSoup, text: str, url: str) -> Dict:
        """Analyze authoritativeness signals"""
        signals_found = []
        score = 0
        
        # Check for authority keywords
        for keyword in self.authority_keywords:
            if keyword in text:
                signals_found.append(keyword)
                score += 8
        
        # Check for external citations/references
        external_links = soup.find_all('a', href=re.compile(r'^https?://'))
        authority_domains = [
            'pubmed', 'nih.gov', 'who.int', 'cdc.gov',
            'behdasht.gov.ir', 'fda.gov', 'ncbi',
            'sciencedirect', 'springer', 'wiley'
        ]
        
        authoritative_links = [
            link for link in external_links
            if any(domain in link.get('href', '').lower() for domain in authority_domains)
        ]
        
        if authoritative_links:
            signals_found.append('authoritative_citations')
            score += 20
        
        # Check for references section
        ref_sections = soup.find_all(['section', 'div'], id=re.compile(r'reference|Ù…Ù†Ø§Ø¨Ø¹', re.I))
        if ref_sections or re.search(r'Ù…Ù†Ø§Ø¨Ø¹\s*:?', text, re.I):
            signals_found.append('references_section')
            score += 15
        
        # Check for publication/update dates
        date_patterns = [
            r'ØªØ§Ø±ÛŒØ®\s+Ø§Ù†ØªØ´Ø§Ø±',
            r'Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ',
            r'published|updated',
            r'datePublished|dateModified'
        ]
        
        for pattern in date_patterns:
            if re.search(pattern, text, re.I):
                signals_found.append('publication_date')
                score += 10
                break
        
        # Check for affiliation with institutions
        institution_patterns = [
            r'Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡\s+Ø¹Ù„ÙˆÙ…\s+Ù¾Ø²Ø´Ú©ÛŒ',
            r'Ø¨ÛŒÙ…Ø§Ø±Ø³ØªØ§Ù†',
            r'medical\s+university',
            r'hospital'
        ]
        
        for pattern in institution_patterns:
            if re.search(pattern, text, re.I):
                signals_found.append('institutional_affiliation')
                score += 15
                break
        
        # Normalize score
        score = min(score, 100)
        
        return {
            'score': score,
            'grade': self._get_grade(score),
            'signals_found': signals_found,
            'signal_count': len(signals_found),
            'authoritative_links_count': len(authoritative_links)
        }
    
    def _analyze_trustworthiness(self, soup: BeautifulSoup, text: str) -> Dict:
        """Analyze trustworthiness signals"""
        signals_found = []
        score = 0
        
        # Check for trust keywords
        for keyword in self.trust_keywords:
            if keyword in text:
                signals_found.append(keyword)
                score += 8
        
        # Check for HTTPS
        # (This would be checked from the URL in real implementation)
        signals_found.append('https_enabled')
        score += 10
        
        # Check for contact information
        contact_patterns = [
            r'\+?\d{10,}',  # Phone numbers
            r'[\w\.-]+@[\w\.-]+\.\w+',  # Email
            r'ØªÙ„ÙÙ†|phone|mobile',
            r'Ø¢Ø¯Ø±Ø³|address'
        ]
        
        contact_found = False
        for pattern in contact_patterns:
            if re.search(pattern, text, re.I):
                contact_found = True
                break
        
        if contact_found:
            signals_found.append('contact_information')
            score += 15
        
        # Check for privacy policy
        privacy_links = soup.find_all('a', href=re.compile(r'privacy|Ø­Ø±ÛŒÙ…\s*Ø®ØµÙˆØµÛŒ', re.I))
        if privacy_links or re.search(r'privacy|Ø­Ø±ÛŒÙ…\s*Ø®ØµÙˆØµÛŒ', text, re.I):
            signals_found.append('privacy_policy')
            score += 10
        
        # Check for terms of service
        terms_links = soup.find_all('a', href=re.compile(r'terms|Ù‚ÙˆØ§Ù†ÛŒÙ†', re.I))
        if terms_links:
            signals_found.append('terms_of_service')
            score += 10
        
        # Check for security badges/certifications
        cert_patterns = [
            r'ssl|secure',
            r'enamad|Ù†Ù…Ø§Ø¯ Ø§Ø¹ØªÙ…Ø§Ø¯',
            r'samandehi|Ø³Ø§Ù…Ø§Ù†Ø¯Ù‡ÛŒ',
            r'verified|ØªØ§ÛŒÛŒØ¯\s*Ø´Ø¯Ù‡'
        ]
        
        for pattern in cert_patterns:
            if re.search(pattern, text, re.I):
                signals_found.append('security_badges')
                score += 12
                break
        
        # Check for about page
        about_links = soup.find_all('a', href=re.compile(r'about|Ø¯Ø±Ø¨Ø§Ø±Ù‡', re.I))
        if about_links:
            signals_found.append('about_page')
            score += 8
        
        # Check for social media links
        social_patterns = [
            r'instagram', r'telegram', r'twitter',
            r'facebook', r'linkedin', r'youtube'
        ]
        
        social_count = sum(1 for pattern in social_patterns if re.search(pattern, text, re.I))
        if social_count > 0:
            signals_found.append(f'{social_count}_social_profiles')
            score += min(social_count * 5, 15)  # Max 15 points
        
        # Normalize score
        score = min(score, 100)
        
        return {
            'score': score,
            'grade': self._get_grade(score),
            'signals_found': signals_found,
            'signal_count': len(signals_found)
        }
    
    def _get_grade(self, score: float) -> str:
        """Convert score to letter grade"""
        if score >= 90:
            return 'A'
        elif score >= 80:
            return 'B'
        elif score >= 70:
            return 'C'
        elif score >= 60:
            return 'D'
        else:
            return 'F'
    
    def _detect_website_type(self, soup: BeautifulSoup, text: str, url: str) -> str:
        """Detect website type based on content and keywords"""
        # Count keyword matches
        educational_score = sum(1 for kw in self.educational_keywords if kw in text or kw in url.lower())
        medical_score = sum(1 for kw in self.medical_keywords if kw in text or kw in url.lower())
        ecommerce_score = sum(1 for kw in self.ecommerce_keywords if kw in text or kw in url.lower())
        
        # Check URL patterns
        if any(pattern in url.lower() for pattern in ['/course', '/training', '/learn', '/Ø¢Ù…ÙˆØ²Ø´', '/Ø¯ÙˆØ±Ù‡']):
            educational_score += 3
        if any(pattern in url.lower() for pattern in ['/doctor', '/clinic', '/hospital', '/Ù¾Ø²Ø´Ú©', '/Ú©Ù„ÛŒÙ†ÛŒÚ©']):
            medical_score += 3
        if any(pattern in url.lower() for pattern in ['/shop', '/product', '/buy', '/Ø®Ø±ÛŒØ¯', '/ÙØ±ÙˆØ´']):
            ecommerce_score += 3
        
        # Determine type
        if educational_score > medical_score and educational_score > ecommerce_score:
            return 'educational'
        elif medical_score > educational_score and medical_score > ecommerce_score:
            return 'medical'
        elif ecommerce_score > educational_score and ecommerce_score > medical_score:
            return 'ecommerce'
        else:
            return 'general'
    
    def _generate_expertise_recommendations(self, expertise: Dict, soup: BeautifulSoup, text: str, website_type: str) -> List[str]:
        """Generate expertise-specific recommendations based on website type"""
        recommendations = []
        
        # Check if author bio exists
        author_sections = soup.find_all(['section', 'div'], class_=re.compile(r'author|writer|bio|instructor|teacher', re.I))
        if not author_sections:
            if website_type == 'educational':
                recommendations.append("âœï¸ Add a detailed instructor/teacher bio section with teaching credentials, education, and experience")
            elif website_type == 'medical':
                recommendations.append("âœï¸ Add a detailed doctor/physician bio section with medical credentials, education, and specialization")
            else:
                recommendations.append("âœï¸ Add a detailed author bio section with credentials, education, and professional background")
        
        # Check for Person schema
        scripts = soup.find_all('script', type='application/ld+json')
        has_person_schema = False
        for script in scripts:
            try:
                import json
                data = json.loads(script.string)
                if isinstance(data, dict) and (data.get('@type') == 'Person' or 'author' in data):
                    has_person_schema = True
                    break
            except:
                pass
        
        if not has_person_schema:
            if website_type == 'educational':
                recommendations.append("ğŸ‘¨â€ğŸ« Implement Person schema (JSON-LD) for instructor/teacher profile with teaching credentials")
            elif website_type == 'medical':
                recommendations.append("ğŸ‘¨â€âš•ï¸ Implement Person schema (JSON-LD) for doctor/physician profile with medical credentials")
            else:
                recommendations.append("ğŸ‘¤ Implement Person schema (JSON-LD) for author profile with credentials")
        
        # Type-specific recommendations
        if website_type == 'educational':
            if expertise['score'] < 50:
                recommendations.append("ğŸ“ Display teaching certifications, educational degrees, and professional qualifications")
                recommendations.append("ğŸ“š Mention courses taught, student success rates, and teaching experience")
            if expertise['score'] < 70:
                recommendations.append("ğŸ† Highlight teaching awards, recognitions, and educational achievements")
                recommendations.append("ğŸ“– Showcase published educational content, tutorials, or course materials")
        elif website_type == 'medical':
            if expertise['score'] < 50:
                recommendations.append("ğŸ“ Mention relevant medical certifications, board memberships, and professional qualifications")
                recommendations.append("ğŸ“œ Display educational background (university, medical school, degrees)")
            if expertise['score'] < 70:
                recommendations.append("ğŸ† Highlight medical awards, recognitions, and professional achievements")
                recommendations.append("ğŸ“š Mention medical publications, research papers, or contributions to the field")
        else:
            if expertise['score'] < 50:
                recommendations.append("ğŸ“ Mention relevant certifications, qualifications, and professional background")
                recommendations.append("ğŸ“œ Display educational background and professional training")
            if expertise['score'] < 70:
                recommendations.append("ğŸ† Highlight awards, recognitions, and professional achievements")
                recommendations.append("ğŸ“š Mention publications, articles, or contributions to your field")
        
        if not recommendations:
            recommendations.append("âœ… Good expertise signals detected. Continue maintaining credentials and qualifications.")
        
        return recommendations
    
    def _generate_experience_recommendations(self, experience: Dict, soup: BeautifulSoup, text: str, website_type: str) -> List[str]:
        """Generate experience-specific recommendations based on website type"""
        recommendations = []
        
        # Check for portfolio/images
        images = soup.find_all('img')
        portfolio_images = [
            img for img in images
            if any(term in img.get('alt', '').lower() for term in ['Ù‚Ø¨Ù„', 'Ø¨Ø¹Ø¯', 'before', 'after', 'Ù†Ù…ÙˆÙ†Ù‡', 'portfolio', 'student', 'Ú©Ø§Ø±'])
        ]
        
        # Check for testimonials
        review_sections = soup.find_all(['div', 'section'], class_=re.compile(r'review|testimonial|Ù†Ø¸Ø±|student|feedback', re.I))
        
        # Check for years of experience
        years_pattern = r'(\d+)\s*(Ø³Ø§Ù„|year).*?(ØªØ¬Ø±Ø¨Ù‡|Ø³Ø§Ø¨Ù‚Ù‡|experience|teaching)'
        has_years = re.search(years_pattern, text, re.I)
        
        if website_type == 'educational':
            if not portfolio_images:
                recommendations.append("ğŸ“· Add student work examples, course completion certificates, or success stories with images")
            if not review_sections:
                recommendations.append("â­ Include student testimonials, reviews, and success stories")
            if not has_years:
                recommendations.append("ğŸ“Š Mention years of teaching experience and number of students taught")
            if experience['score'] < 50:
                recommendations.append("ğŸ“ˆ Add statistics: number of students, course completion rates, student satisfaction")
                recommendations.append("ğŸ¬ Include video testimonials from successful students")
            if experience['score'] < 70:
                recommendations.append("ğŸ“‹ Create detailed case studies showing student progress and achievements")
                recommendations.append("ğŸ… Display teaching milestones, certifications, and educational achievements")
        elif website_type == 'medical':
            if not portfolio_images:
                recommendations.append("ğŸ“· Add before/after portfolio images with descriptive alt text")
            if not review_sections:
                recommendations.append("â­ Include patient testimonials, reviews, and case studies")
            if not has_years:
                recommendations.append("ğŸ“Š Mention years of experience and number of cases/patients treated")
            if experience['score'] < 50:
                recommendations.append("ğŸ“ˆ Add statistics: number of successful cases, patient satisfaction rate")
                recommendations.append("ğŸ¬ Include video testimonials or patient success stories")
            if experience['score'] < 70:
                recommendations.append("ğŸ“‹ Create detailed case studies with before/after results")
                recommendations.append("ğŸ… Display professional milestones and career highlights")
        else:
            if not portfolio_images:
                recommendations.append("ğŸ“· Add portfolio images, project examples, or work samples with descriptive alt text")
            if not review_sections:
                recommendations.append("â­ Include client testimonials, reviews, and case studies")
            if not has_years:
                recommendations.append("ğŸ“Š Mention years of experience and number of projects/clients")
            if experience['score'] < 50:
                recommendations.append("ğŸ“ˆ Add statistics: number of successful projects, client satisfaction rate")
                recommendations.append("ğŸ¬ Include video testimonials or success stories")
            if experience['score'] < 70:
                recommendations.append("ğŸ“‹ Create detailed case studies showing project results")
                recommendations.append("ğŸ… Display professional milestones and career highlights")
        
        if not recommendations:
            recommendations.append("âœ… Good experience signals detected. Continue showcasing your work and achievements.")
        
        return recommendations
    
    def _generate_authoritativeness_recommendations(self, authoritativeness: Dict, soup: BeautifulSoup, text: str, website_type: str) -> List[str]:
        """Generate authoritativeness-specific recommendations based on website type"""
        recommendations = []
        
        # Check for external citations
        external_links = soup.find_all('a', href=re.compile(r'^https?://'))
        
        if website_type == 'educational':
            authority_domains = [
                'coursera', 'udemy', 'edx', 'khan academy', 'ted', 'youtube.com/education',
                'wikipedia', 'stackoverflow', 'github', 'medium', 'towards data science',
                'ministry of education', 'ÙˆØ²Ø§Ø±Øª Ø¢Ù…ÙˆØ²Ø´', 'Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡'
            ]
            authoritative_links = [
                link for link in external_links
                if any(domain in link.get('href', '').lower() for domain in authority_domains)
            ]
            
            if not authoritative_links:
                recommendations.append("ğŸ“š Add references to authoritative educational sources (Coursera, Udemy, educational institutions, Wikipedia)")
        elif website_type == 'medical':
            authority_domains = [
                'pubmed', 'nih.gov', 'who.int', 'cdc.gov',
                'behdasht.gov.ir', 'fda.gov', 'ncbi',
                'sciencedirect', 'springer', 'wiley'
            ]
            authoritative_links = [
                link for link in external_links
                if any(domain in link.get('href', '').lower() for domain in authority_domains)
            ]
            
            if not authoritative_links:
                recommendations.append("ğŸ“š Add references to authoritative sources (PubMed, medical journals, WHO, FDA)")
        else:
            authority_domains = [
                'wikipedia', 'gov', 'edu', 'org', 'research', 'study'
            ]
            authoritative_links = [
                link for link in external_links
                if any(domain in link.get('href', '').lower() for domain in authority_domains)
            ]
            
            if not authoritative_links:
                recommendations.append("ğŸ“š Add references to authoritative sources relevant to your field")
        
        # Check for references section
        ref_sections = soup.find_all(['section', 'div'], id=re.compile(r'reference|Ù…Ù†Ø§Ø¨Ø¹|sources', re.I))
        if not ref_sections and not re.search(r'Ù…Ù†Ø§Ø¨Ø¹|references|sources', text, re.I):
            if website_type == 'educational':
                recommendations.append("ğŸ“– Create a references section citing educational resources, tutorials, and learning materials")
            elif website_type == 'medical':
                recommendations.append("ğŸ“– Create a references section citing medical journals and research papers")
            else:
                recommendations.append("ğŸ“– Create a references section citing authoritative sources")
        
        # Check for publication dates
        date_patterns = [
            r'ØªØ§Ø±ÛŒØ®\s+Ø§Ù†ØªØ´Ø§Ø±',
            r'Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ',
            r'published|updated',
            r'datePublished|dateModified'
        ]
        
        has_date = any(re.search(pattern, text, re.I) for pattern in date_patterns)
        if not has_date:
            recommendations.append("ğŸ“… Include publication date and last updated date to show content freshness")
        
        if website_type == 'educational':
            if authoritativeness['score'] < 50:
                recommendations.append("ğŸ« Mention educational affiliations (universities, training centers, educational institutions)")
                recommendations.append("ğŸ”— Link to authoritative educational sources and learning platforms")
            if authoritativeness['score'] < 70:
                recommendations.append("ğŸ“ Cite recent educational research, teaching methodologies, and best practices")
                recommendations.append("ğŸŒ Get backlinks from educational websites, blogs, and learning communities")
        elif website_type == 'medical':
            if authoritativeness['score'] < 50:
                recommendations.append("ğŸ¥ Mention institutional affiliations (hospitals, universities, medical centers)")
                recommendations.append("ğŸ”— Link to authoritative external sources and research papers")
            if authoritativeness['score'] < 70:
                recommendations.append("ğŸ“ Cite recent studies and medical research relevant to your content")
                recommendations.append("ğŸŒ Get backlinks from authoritative medical websites and organizations")
        else:
            if authoritativeness['score'] < 50:
                recommendations.append("ğŸ¢ Mention professional affiliations and industry associations")
                recommendations.append("ğŸ”— Link to authoritative external sources in your field")
            if authoritativeness['score'] < 70:
                recommendations.append("ğŸ“ Cite recent research, studies, and industry best practices")
                recommendations.append("ğŸŒ Get backlinks from authoritative websites in your industry")
        
        if not recommendations:
            recommendations.append("âœ… Good authoritativeness signals detected. Continue citing authoritative sources.")
        
        return recommendations
    
    def _generate_trustworthiness_recommendations(self, trustworthiness: Dict, soup: BeautifulSoup, text: str, website_type: str) -> List[str]:
        """Generate trustworthiness-specific recommendations based on website type"""
        recommendations = []
        
        # Check for contact information
        contact_patterns = [
            r'\+?\d{10,}',
            r'[\w\.-]+@[\w\.-]+\.\w+',
            r'ØªÙ„ÙÙ†|phone|mobile',
            r'Ø¢Ø¯Ø±Ø³|address'
        ]
        
        contact_found = any(re.search(pattern, text, re.I) for pattern in contact_patterns)
        if not contact_found:
            recommendations.append("ğŸ“ Add complete contact information (phone, email, physical address)")
        
        # Check for privacy policy
        privacy_links = soup.find_all('a', href=re.compile(r'privacy|Ø­Ø±ÛŒÙ…\s*Ø®ØµÙˆØµÛŒ', re.I))
        if not privacy_links and not re.search(r'privacy|Ø­Ø±ÛŒÙ…\s*Ø®ØµÙˆØµÛŒ', text, re.I):
            recommendations.append("ğŸ”’ Add privacy policy page and link to it in footer")
        
        # Check for terms of service
        terms_links = soup.find_all('a', href=re.compile(r'terms|Ù‚ÙˆØ§Ù†ÛŒÙ†', re.I))
        if not terms_links:
            if website_type == 'educational':
                recommendations.append("ğŸ“‹ Add terms of service and refund policy for course purchases")
            else:
                recommendations.append("ğŸ“‹ Add terms of service page for legal transparency")
        
        # Check for security badges
        cert_patterns = [
            r'ssl|secure',
            r'enamad|Ù†Ù…Ø§Ø¯ Ø§Ø¹ØªÙ…Ø§Ø¯',
            r'samandehi|Ø³Ø§Ù…Ø§Ù†Ø¯Ù‡ÛŒ',
            r'verified|ØªØ§ÛŒÛŒØ¯\s*Ø´Ø¯Ù‡'
        ]
        
        has_cert = any(re.search(pattern, text, re.I) for pattern in cert_patterns)
        if not has_cert:
            recommendations.append("âœ… Display trust badges (eNamad, Samandehi, SSL certificate)")
        
        # Check for social media
        social_patterns = [
            r'instagram', r'telegram', r'twitter',
            r'facebook', r'linkedin', r'youtube'
        ]
        
        social_count = sum(1 for pattern in social_patterns if re.search(pattern, text, re.I))
        if social_count < 2:
            recommendations.append("ğŸ‘¥ Add social media profiles (Instagram, Telegram, LinkedIn) with verification")
        
        if website_type == 'educational':
            if trustworthiness['score'] < 50:
                recommendations.append("ğŸ†” Display educational licenses, teaching certifications, and accreditations")
                recommendations.append("ğŸ“¸ Add real photos of instructors, classrooms, or learning environment")
            if trustworthiness['score'] < 70:
                recommendations.append("ğŸ’¬ Add live chat or quick contact form for student inquiries")
                recommendations.append("â­ Display student reviews and ratings from trusted platforms")
        elif website_type == 'medical':
            if trustworthiness['score'] < 50:
                recommendations.append("ğŸ†” Display professional licenses and medical certifications prominently")
                recommendations.append("ğŸ“¸ Add real photos of the team/facility to build trust")
            if trustworthiness['score'] < 70:
                recommendations.append("ğŸ’¬ Add live chat or quick contact form for easy communication")
                recommendations.append("â­ Display patient reviews and ratings from trusted platforms")
        else:
            if trustworthiness['score'] < 50:
                recommendations.append("ğŸ†” Display professional licenses and certifications prominently")
                recommendations.append("ğŸ“¸ Add real photos of the team/facility to build trust")
            if trustworthiness['score'] < 70:
                recommendations.append("ğŸ’¬ Add live chat or quick contact form for easy communication")
                recommendations.append("â­ Display customer reviews and ratings from trusted platforms")
        
        if not recommendations:
            recommendations.append("âœ… Good trustworthiness signals detected. Continue maintaining transparency and trust.")
        
        return recommendations
    
    def _generate_recommendations(self, expertise, experience, authoritativeness, trustworthiness) -> List[str]:
        """Generate overall actionable recommendations"""
        recommendations = []
        
        # Overall priority recommendations
        if expertise['score'] < 70:
            recommendations.append("ğŸ“ Priority: Improve expertise signals by adding author credentials and qualifications")
        
        if experience['score'] < 70:
            recommendations.append("â­ Priority: Showcase experience through portfolio, testimonials, and case studies")
        
        if authoritativeness['score'] < 70:
            recommendations.append("ğŸ“š Priority: Build authoritativeness by citing authoritative sources and research")
        
        if trustworthiness['score'] < 70:
            recommendations.append("ğŸ”’ Priority: Enhance trustworthiness with contact info, policies, and trust badges")
        
        return recommendations


# ==================== Example Usage ====================

if __name__ == "__main__":
    # Test HTML
    test_html = """
    <html>
    <head>
        <script type="application/ld+json">
        {
            "@context": "https://schema.org",
            "@type": "Person",
            "name": "Ø¯Ú©ØªØ± Ù…Ø­Ù…Ø¯ Ø±Ø¶Ø§ÛŒÛŒ",
            "jobTitle": "Ù…ØªØ®ØµØµ Ù¾ÙˆØ³Øª Ùˆ Ù…Ùˆ",
            "affiliation": {
                "@type": "Organization",
                "name": "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø¹Ù„ÙˆÙ… Ù¾Ø²Ø´Ú©ÛŒ ØªÙ‡Ø±Ø§Ù†"
            }
        }
        </script>
    </head>
    <body>
        <h1>Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ø¯Ú©ØªØ±</h1>
        <p>Ø¯Ú©ØªØ± Ù…Ø­Ù…Ø¯ Ø±Ø¶Ø§ÛŒÛŒ Ø¨Ø§ 15 Ø³Ø§Ù„ Ø³Ø§Ø¨Ù‚Ù‡ Ø¯Ø± Ø²Ù…ÛŒÙ†Ù‡ Ù¾ÙˆØ³Øª Ùˆ Ù…Ùˆ ÙØ¹Ø§Ù„ÛŒØª Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
        Ø§ÛŒØ´Ø§Ù† Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ®ØªÙ‡ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø¹Ù„ÙˆÙ… Ù¾Ø²Ø´Ú©ÛŒ ØªÙ‡Ø±Ø§Ù† Ùˆ Ø¯Ø§Ø±Ø§ÛŒ ÙÙ„ÙˆØ´ÛŒÙ¾ Ø§Ø² Ú©Ø´ÙˆØ± Ø¢Ù„Ù…Ø§Ù† Ù‡Ø³ØªÙ†Ø¯.</p>
        
        <h2>Ù†Ù…ÙˆÙ†Ù‡ Ú©Ø§Ø±Ù‡Ø§</h2>
        <img src="before.jpg" alt="Ù‚Ø¨Ù„ Ø§Ø² Ù„ÛŒØ²Ø±">
        <img src="after.jpg" alt="Ø¨Ø¹Ø¯ Ø§Ø² Ù„ÛŒØ²Ø±">
        
        <h2>Ù†Ø¸Ø±Ø§Øª Ø¨ÛŒÙ…Ø§Ø±Ø§Ù†</h2>
        <div class="testimonials">
            <p>Ø¨Ø³ÛŒØ§Ø± Ø±Ø§Ø¶ÛŒ Ù‡Ø³ØªÙ… - Ø®Ø§Ù†Ù… Ø§Ø­Ù…Ø¯ÛŒ</p>
        </div>
        
        <h2>Ù…Ù†Ø§Ø¨Ø¹</h2>
        <p>Ù…Ø·Ø§Ù„Ø¹Ø§Øª Ø¹Ù„Ù…ÛŒ Ø§Ø² 
        <a href="https://pubmed.ncbi.nlm.nih.gov/">PubMed</a>
        Ùˆ <a href="https://behdasht.gov.ir/">ÙˆØ²Ø§Ø±Øª Ø¨Ù‡Ø¯Ø§Ø´Øª</a>
        </p>
        
        <footer>
            <p>ØªÙ„ÙÙ†: 02188888888</p>
            <p>Ø¢Ø¯Ø±Ø³: ØªÙ‡Ø±Ø§Ù†ØŒ Ø³Ø¹Ø§Ø¯Øªâ€ŒØ¢Ø¨Ø§Ø¯</p>
            <a href="/privacy">Ø­Ø±ÛŒÙ… Ø®ØµÙˆØµÛŒ</a>
            <img src="enamad.png" alt="Ù†Ù…Ø§Ø¯ Ø§Ø¹ØªÙ…Ø§Ø¯ Ø§Ù„Ú©ØªØ±ÙˆÙ†ÛŒÚ©ÛŒ">
        </footer>
    </body>
    </html>
    """
    
    soup = BeautifulSoup(test_html, 'html.parser')
    analyzer = EEATAnalyzer()
    
    print("\n" + "="*70)
    print("ğŸ† E-E-A-T ANALYZER TEST")
    print("="*70 + "\n")
    
    # Analyze
    results = analyzer.analyze_eeat(soup, "https://example.com/about-doctor/")
    
    print(f"ğŸ“Š Overall E-E-A-T Score: {results['overall_score']}/100 (Grade: {results['overall_grade']})\n")
    
    print(f"ğŸ“ Expertise: {results['expertise']['score']}/100 (Grade: {results['expertise']['grade']})")
    print(f"   Signals: {', '.join(results['expertise']['signals_found'][:5])}\n")
    
    print(f"â­ Experience: {results['experience']['score']}/100 (Grade: {results['experience']['grade']})")
    print(f"   Signals: {', '.join(results['experience']['signals_found'][:5])}\n")
    
    print(f"ğŸ“š Authoritativeness: {results['authoritativeness']['score']}/100 (Grade: {results['authoritativeness']['grade']})")
    print(f"   Signals: {', '.join(results['authoritativeness']['signals_found'][:5])}")
    print(f"   Authoritative Links: {results['authoritativeness']['authoritative_links_count']}\n")
    
    print(f"ğŸ”’ Trustworthiness: {results['trustworthiness']['score']}/100 (Grade: {results['trustworthiness']['grade']})")
    print(f"   Signals: {', '.join(results['trustworthiness']['signals_found'][:5])}\n")
    
    if results['recommendations']:
        print("ğŸ’¡ Recommendations:")
        for rec in results['recommendations'][:8]:
            print(f"   {rec}")


